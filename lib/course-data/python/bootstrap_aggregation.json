{
  "title": "Python Machine Learning - Bootstrap Aggregation (Bagging)",
  "url": "https://www.w3schools.com/python/python_ml_bagging.asp",
  "metadata": {
    "viewport": "width=device-width, initial-scale=1",
    "title": "W3Schools.com",
    "Keywords": "HTML, Python, CSS, SQL, JavaScript, How to, PHP, Java, C, C++, C#, jQuery, Bootstrap, Colors, W3.CSS, XML, MySQL, Icons, NodeJS, React, Graphics, Angular, R, AI, Git, Data Science, Code Game, Tutorials, Programming, Web Development, Training, Learning, Quiz, Exercises, Courses, Lessons, References, Examples, Learn to code, Source code, Demos, Tips, Website",
    "Description": "Well organized and easy to understand Web building tutorials with lots of examples of how to use HTML, CSS, JavaScript, SQL, Python, PHP, Bootstrap, Java, XML and more.",
    "og:image": "https://www.w3schools.com/images/w3schools_logo_436_2.png",
    "og:image:type": "image/png",
    "og:image:width": "436",
    "og:image:height": "228",
    "og:description": "W3Schools offers free online tutorials, references and exercises in all the major languages of the web. Covering popular subjects like HTML, CSS, JavaScript, Python, SQL, Java, and many, many more.",
    "msapplication-TileColor": "#00a300",
    "theme-color": "#ffffff",
    "keywords": "HTML, Python, CSS, SQL, JavaScript, How to, PHP, Java, C, C++, C#, jQuery, Bootstrap, Colors, W3.CSS, XML, MySQL, Icons, NodeJS, React, Graphics, Angular, R, AI, Git, Data Science, Code Game, Tutorials, Programming, Web Development, Training, Learning, Quiz, Exercises, Courses, Lessons, References, Examples, Learn to code, Source code, Demos, Tips, Website"
  },
  "content": [
    {
      "type": "header",
      "metadata": {
        "level": "h1"
      },
      "text": "Machine Learning - Bootstrap Aggregation (Bagging)",
      "level": "h1"
    },
    {
      "type": "text",
      "metadata": {},
      "links": [
        {
          "text": "\nNYC Data Science Academy",
          "href": "https://t.sidekickopen01.com/s3t/c/5/f18dQhb0S7kv8c7RP2W1z75qk59hl3kW7_k2847tBZxCVvfv0f1GTV9PW2RxlDT2bzNMYdZ8s8G01?te=W3R5hFj4cm2zwW41-DxM3zhrr_W3F7ZBj3F6bSSW43T4N94hMnzcW3F4Fvd3zbTMqW2fgYK73F7y_5W3Zp0KM3_Qh5fW4hLxLG2f1Dw_W3F7y_53Zp0KMW3_QgzD3H6xvkW2dTzCR3SYMmGW1mp5CL3ZWTYrW4cbSf23_Qh9QW49NMw73HdlCPW3Hbzjf4fKWwkW43TDjD41YtR1W3zbVlf1S1tRf38WL2&si=6321147182055424&pi=566c78b2-d5c2-45ad-ad0c-74291c07630b",
          "title": ""
        }
      ],
      "text": "On this page, W3schools.com collaborates with NYC Data Science Academy , to deliver digital training content to our students.",
      "html": "<p>On this page, W3schools.com collaborates with <a href=\"https://t.sidekickopen01.com/s3t/c/5/f18dQhb0S7kv8c7RP2W1z75qk59hl3kW7_k2847tBZxCVvfv0f1GTV9PW2RxlDT2bzNMYdZ8s8G01?te=W3R5hFj4cm2zwW41-DxM3zhrr_W3F7ZBj3F6bSSW43T4N94hMnzcW3F4Fvd3zbTMqW2fgYK73F7y_5W3Zp0KM3_Qh5fW4hLxLG2f1Dw_W3F7y_53Zp0KMW3_QgzD3H6xvkW2dTzCR3SYMmGW1mp5CL3ZWTYrW4cbSf23_Qh9QW49NMw73HdlCPW3Hbzjf4fKWwkW43TDjD41YtR1W3zbVlf1S1tRf38WL2&amp;si=6321147182055424&amp;pi=566c78b2-d5c2-45ad-ad0c-74291c07630b\" target=\"_blank\">\nNYC Data Science Academy</a>, to deliver digital training content to our students.</p>"
    },
    {
      "type": "header",
      "metadata": {
        "level": "h2"
      },
      "text": "Bagging",
      "level": "h2"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Methods such as Decision Trees, can be prone to overfitting on the training set which can lead to wrong predictions on new data.",
      "html": "<p>Methods such as Decision Trees, can be prone to overfitting on the training set which can lead to wrong predictions on new data.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Bootstrap Aggregation (bagging) is a ensembling method that attempts to resolve overfitting for classification or regression problems. Bagging aims to improve the accuracy and performance of machine learning algorithms. It does this by taking random subsets of an original dataset, with replacement, and fits either a classifier (for classification) or regressor (for regression) to each subset. The predictions for each subset are then aggregated through majority vote for classification or averaging for regression, increasing prediction accuracy.",
      "html": "<p>Bootstrap Aggregation (bagging) is a ensembling method that attempts to resolve overfitting for classification or regression problems. Bagging aims to improve the accuracy and performance of machine learning algorithms. It does this by taking random subsets of an original dataset, with replacement, and fits either a classifier (for classification) or regressor (for regression) to each subset. The predictions for each subset are then aggregated through majority vote for classification or averaging for regression, increasing prediction accuracy.</p>"
    },
    {
      "type": "header",
      "metadata": {
        "level": "h2"
      },
      "text": "Evaluating a Base Classifier",
      "level": "h2"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "To see how bagging can improve model performance, we must start by evaluating how the base classifier performs on the dataset. If you do not know what decision trees are review the lesson on decision trees before moving forward, as bagging is a continuation of the concept.",
      "html": "<p>To see how bagging can improve model performance, we must start by evaluating how the base classifier performs on the dataset. If you do not know what decision trees are review the lesson on decision trees before moving forward, as bagging is a continuation of the concept.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "We will be looking to identify different classes of wines found in Sklearn's wine dataset.",
      "html": "<p>We will be looking to identify different classes of wines found in Sklearn's wine dataset.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "python",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "from sklearn import datasets from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn.tree import DecisionTreeClassifier",
      "language": "python",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Next we need to load in the data and store it into X (input features) and y (target). The parameter as_frame is set equal to True so we do not lose the feature names when loading the data. ( sklearn version older than 0.23 must skip the as_frame argument as it is not supported)",
      "html": "<p>Next we need to load in the data and store it into X (input features) and y (target). The parameter as_frame is set equal to True so we do not lose the feature names when loading the data. \n(<code>sklearn</code> version older than 0.23 must skip the\n<code>as_frame</code> argument as it is not supported) </p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "data = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "True",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "data = datasets.load_wine(as_frame = True ) X = data.data y = data.target",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "data = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "True",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "In order to properly evaluate our model on unseen data, we need to split X and y into train and test sets. For information on splitting data, see the Train/Test lesson.",
      "html": "<p>In order to properly evaluate our model on unseen data, we need to split X and y into train and test sets. For information on splitting data, see the Train/Test lesson.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22) ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "0.25",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25 , random_state = 22 )",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22) ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "0.25",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "With our data prepared, we can now instantiate a base classifier and fit it to the training data.",
      "html": "<p>With our data prepared, we can now instantiate a base classifier and fit it to the training data.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "dtree = DecisionTreeClassifier(random_state = 22)\ndtree.fit(X_train,y_train) ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "dtree = DecisionTreeClassifier(random_state = 22 ) dtree.fit(X_train,y_train)",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "dtree = DecisionTreeClassifier(random_state = 22)\ndtree.fit(X_train,y_train) ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Result:",
      "html": "<p>Result:</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "DecisionTreeClassifier(random_state=22) ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "DecisionTreeClassifier(random_state= 22 )",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "DecisionTreeClassifier(random_state=22) ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "We can now predict the class of wine the unseen test set and evaluate the model performance.",
      "html": "<p>We can now predict the class of wine the unseen test set and evaluate the model performance.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "y_pred = dtree.predict(X_test)\n\nprint(\"Train data accuracy:\",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))\nprint(\"Test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred)) ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "print",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\"Train data accuracy:\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          },
          {
            "text": "print",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\"Test data accuracy:\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "y_pred = dtree.predict(X_test) print ( \"Train data accuracy:\" ,accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train))) print ( \"Test data accuracy:\" ,accuracy_score(y_true = y_test, y_pred = y_pred))",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "y_pred = dtree.predict(X_test)\n\nprint(\"Train data accuracy:\",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))\nprint(\"Test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred)) ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "print",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\"Train data accuracy:\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        },
        {
          "text": "print",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\"Test data accuracy:\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Result:",
      "html": "<p>Result:</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "Train data accuracy: 1.0\nTest data accuracy: 0.8222222222222222 ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "1.0",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "0.8222222222222222",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "Train data accuracy: 1.0 Test data accuracy: 0.8222222222222222",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "Train data accuracy: 1.0\nTest data accuracy: 0.8222222222222222 ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "1.0",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "0.8222222222222222",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "code",
      "metadata": {
        "language": "python",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\ndtree = DecisionTreeClassifier(random_state = 22)\ndtree.fit(X_train,y_train)\n\ny_pred = dtree.predict(X_test)\n\nprint(\"Train data accuracy:\",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))\nprint(\"Test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred))\n\n ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "True",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "0.25",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "print",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\"Train data accuracy:\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          },
          {
            "text": "print",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\"Test data accuracy:\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          },
          {
            "text": "\n\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-code",
          "notranslate",
          "pythonHigh"
        ],
        "isNotranslate": true
      },
      "code": "from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\ndtree = DecisionTreeClassifier(random_state = 22)\ndtree.fit(X_train,y_train)\n\ny_pred = dtree.predict(X_test)\n\nprint(\"Train data accuracy:\",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))\nprint(\"Test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred))",
      "syntax_highlighting": [
        {
          "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\ndtree = DecisionTreeClassifier(random_state = 22)\ndtree.fit(X_train,y_train)\n\ny_pred = dtree.predict(X_test)\n\nprint(\"Train data accuracy:\",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))\nprint(\"Test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred))\n ",
          "color": "black",
          "class": [
            "pythoncolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "True",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "0.25",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "print",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\"Train data accuracy:\"",
          "color": "green",
          "class": [
            "pythonstringcolor"
          ]
        },
        {
          "text": "print",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\"Test data accuracy:\"",
          "color": "green",
          "class": [
            "pythonstringcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        }
      ],
      "language": "html",
      "code_html": "<div class=\"w3-code notranslate pythonHigh\"><span class=\"pythoncolor\" style=\"color:black\">\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> datasets<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.model_selection <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> train_test_split<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.metrics <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> accuracy_score<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.tree <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> DecisionTreeClassifier<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\ndata = datasets.load_wine(as_frame = <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">True</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX = data.data<br/>\ny = data.target<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class=\"pythonnumbercolor\" style=\"color:#905\">0.25</span>, random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\ndtree = DecisionTreeClassifier(random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/>\ndtree.fit(X_train,y_train)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\ny_pred = dtree.predict(X_test)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">print</span>(<span class=\"pythonstringcolor\" style=\"color:green\">\"Train data accuracy:\"</span>,accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">print</span>(<span class=\"pythonstringcolor\" style=\"color:green\">\"Test data accuracy:\"</span>,accuracy_score(y_true = y_test, y_pred = y_pred))<span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span> </span></div>",
      "code_classes": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\ndtree = DecisionTreeClassifier(random_state = 22)\ndtree.fit(X_train,y_train)\n\ny_pred = dtree.predict(X_test)\n\nprint(\"Train data accuracy:\",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))\nprint(\"Test data accuracy:\",accuracy_score(y_true = y_test, y_pred = y_pred))\n\n ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "True",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "0.25",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "print",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\"Train data accuracy:\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        },
        {
          "text": "print",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\"Test data accuracy:\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        },
        {
          "text": "\n\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "is_notranslate": true
    },
    {
      "type": "text",
      "metadata": {},
      "text": "The base classifier performs reasonably well on the dataset achieving 82% accuracy on the test dataset with the current parameters (Different results may occur if you do not have the random_state parameter set).",
      "html": "<p>The base classifier performs reasonably well on the dataset achieving 82% accuracy on the test dataset with the current parameters (Different results may occur if you do not have the <code>random_state</code> parameter set).</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Now that we have a baseline accuracy for the test dataset, we can see how the Bagging Classifier out performs a single Decision Tree Classifier.",
      "html": "<p>Now that we have a baseline accuracy for the test dataset, we can see how the Bagging Classifier out performs a single Decision Tree Classifier.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "ADVERTISEMENT",
      "html": "<p style=\"text-align:center;font-size:80%;\">ADVERTISEMENT</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "links": [
        {
          "text": "NYCDSA",
          "href": "https://nycdatascience.edu/about-us/?utm_campaign=w3school&utm_source=W3school&utm_medium=display%20Ads&utm_term=PPC&utm_content=About%20Us%20video",
          "title": ""
        }
      ],
      "text": "Learn more about NYCDSA",
      "html": "<p>Learn more about <a href=\"https://nycdatascience.edu/about-us/?utm_campaign=w3school&amp;utm_source=W3school&amp;utm_medium=display%20Ads&amp;utm_term=PPC&amp;utm_content=About%20Us%20video\" target=\"_blank\">NYCDSA</a></p>"
    },
    {
      "type": "header",
      "metadata": {
        "level": "h2"
      },
      "text": "Creating a Bagging Classifier",
      "level": "h2"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "For bagging we need to set the parameter n_estimators, this is the number of base classifiers that our model is going to aggregate together.",
      "html": "<p>For bagging we need to set the parameter n_estimators, this is the number of base classifiers that our model is going to aggregate together.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "links": [
        {
          "text": "grid search",
          "href": "https://www.w3schools.com/python_ml_grid_search.asp",
          "title": ""
        }
      ],
      "text": "For this sample dataset the number of estimators is relatively low, it is often the case that much larger ranges are explored. Hyperparameter tuning is usually done with a grid search , but for now we will use a select set of values for the number of estimators.",
      "html": "<p>For this sample dataset the number of estimators is relatively low, it is often the case that much larger ranges are explored. Hyperparameter tuning is usually done with a \n<a href=\"python_ml_grid_search.asp\">grid search</a>, but for now we will use a select set of values for the number of estimators.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "We start by importing the necessary model.",
      "html": "<p>We start by importing the necessary model.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "python",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "from sklearn.ensemble import BaggingClassifier ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "from sklearn.ensemble import BaggingClassifier",
      "language": "python",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "from sklearn.ensemble import BaggingClassifier ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Now lets create a range of values that represent the number of estimators we want to use in each ensemble.",
      "html": "<p>Now lets create a range of values that represent the number of estimators we want to use in each ensemble.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "estimator_range = [2,4,6,8,10,12,14,16] ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "2",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "4",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "6",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "8",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "10",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "12",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "14",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "16",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "estimator_range = [ 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 ]",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "estimator_range = [2,4,6,8,10,12,14,16] ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "2",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "4",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "6",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "8",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "10",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "12",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "14",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "16",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "To see how the Bagging Classifier performs with differing values of n_estimators we need a way to iterate over the range of values and store the results from each ensemble. To do this we will create a for loop, storing the models and scores in separate lists for later visualizations.",
      "html": "<p>To see how the Bagging Classifier performs with differing values of n_estimators we need a way to iterate over the range of values and store the results from each ensemble. To do this we will create a for loop, storing the models and scores in separate lists for later \nvisualizations.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Note: The default parameter for the base classifier in BaggingClassifier is the DecisionTreeClassifier therefore we do not need to set it when instantiating the bagging model.",
      "html": "<p>Note: The default parameter for the base classifier in <code>BaggingClassifier</code> is the <code>DecisionTreeClassifier</code> therefore we do not need to set it when instantiating the bagging model.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "unknown",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "models = []\nscores = []\n\nfor n_estimators in estimator_range:\n    \n\u00a0\u00a0\u00a0\u00a0# Create bagging classifier\n\u00a0\u00a0\u00a0\u00a0clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n    \n\u00a0\u00a0\u00a0\u00a0# Fit the model\n\u00a0\u00a0\u00a0\u00a0clf.fit(X_train, y_train)\n    \n\u00a0\u00a0\u00a0\u00a0# Append the model and score to their respective list\n\u00a0\u00a0\u00a0\u00a0models.append(clf)\n\u00a0\u00a0\u00a0\u00a0scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test))) ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "for",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "in",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Create bagging classifier",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Fit the model",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Append the model and score to their respective list",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "code": "models = [] scores = [] for n_estimators in estimator_range: # Create bagging classifier clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22 ) # Fit the model clf.fit(X_train, y_train) # Append the model and score to their respective list models.append(clf) scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))",
      "language": "unknown",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "models = []\nscores = []\n\nfor n_estimators in estimator_range:\n    \n\u00a0\u00a0\u00a0\u00a0# Create bagging classifier\n\u00a0\u00a0\u00a0\u00a0clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n    \n\u00a0\u00a0\u00a0\u00a0# Fit the model\n\u00a0\u00a0\u00a0\u00a0clf.fit(X_train, y_train)\n    \n\u00a0\u00a0\u00a0\u00a0# Append the model and score to their respective list\n\u00a0\u00a0\u00a0\u00a0models.append(clf)\n\u00a0\u00a0\u00a0\u00a0scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test))) ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "for",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "in",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Create bagging classifier",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Fit the model",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Append the model and score to their respective list",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "text",
      "metadata": {},
      "text": "With the models and scores stored, we can now visualize the improvement in model performance.",
      "html": "<p>With the models and scores stored, we can now visualize the improvement in model performance.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "python",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "import matplotlib.pyplot as plt\n\n# Generate the plot of scores against number of estimators\nplt.figure(figsize=(9,6))\nplt.plot(estimator_range, scores)\n\n# Adjust labels and font (to make visable)\nplt.xlabel(\"n_estimators\", fontsize = 18)\nplt.ylabel(\"score\", fontsize = 18)\nplt.tick_params(labelsize = 16)\n\n# Visualize plot\nplt.show() ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "as",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Generate the plot of scores against number of estimators",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "9",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "6",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Adjust labels and font (to make visable)",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\"n_estimators\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          },
          {
            "text": "18",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\"score\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          },
          {
            "text": "18",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "16",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Visualize plot",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          }
        ],
        "classList": [
          "w3-example",
          "ws-light-grey"
        ],
        "isNotranslate": false
      },
      "images": [
        {
          "src": "img_ml_bagging2.png",
          "alt": "",
          "title": "",
          "local_path": "/home/ziko/Dev/Scraper/assets/python/img_ml_bagging2.png"
        }
      ],
      "code": "import matplotlib.pyplot as plt # Generate the plot of scores against number of estimators plt.figure(figsize=( 9 , 6 )) plt.plot(estimator_range, scores) # Adjust labels and font (to make visable) plt.xlabel( \"n_estimators\" , fontsize = 18 ) plt.ylabel( \"score\" , fontsize = 18 ) plt.tick_params(labelsize = 16 ) # Visualize plot plt.show()",
      "language": "python",
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "import matplotlib.pyplot as plt\n\n# Generate the plot of scores against number of estimators\nplt.figure(figsize=(9,6))\nplt.plot(estimator_range, scores)\n\n# Adjust labels and font (to make visable)\nplt.xlabel(\"n_estimators\", fontsize = 18)\nplt.ylabel(\"score\", fontsize = 18)\nplt.tick_params(labelsize = 16)\n\n# Visualize plot\nplt.show() ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "as",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Generate the plot of scores against number of estimators",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "9",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "6",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Adjust labels and font (to make visable)",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\"n_estimators\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        },
        {
          "text": "18",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\"score\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        },
        {
          "text": "18",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "16",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Visualize plot",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        }
      ],
      "class_list": [
        "w3-example",
        "ws-light-grey"
      ],
      "is_notranslate": false
    },
    {
      "type": "code",
      "metadata": {
        "language": "python",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nestimator_range = [2,4,6,8,10,12,14,16]\n\nmodels = []\nscores = []\n\nfor n_estimators in estimator_range:\n    \n\u00a0\u00a0\u00a0\u00a0# Create bagging classifier\n\u00a0\u00a0\u00a0\u00a0clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n    \n\u00a0\u00a0\u00a0\u00a0# Fit the model\n\u00a0\u00a0\u00a0\u00a0clf.fit(X_train, y_train)\n    \n\u00a0\u00a0\u00a0\u00a0# Append the model and score to their respective list\n\u00a0\u00a0\u00a0\u00a0models.append(clf)\n\u00a0\u00a0\u00a0\u00a0scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))\n    \n# Generate the plot of scores against number of estimators\nplt.figure(figsize=(9,6))\nplt.plot(estimator_range, scores)\n\n# Adjust labels and font (to make visable)\nplt.xlabel(\"n_estimators\", fontsize = 18)\nplt.ylabel(\"score\", fontsize = 18)\nplt.tick_params(labelsize = 16)\n\n# Visualize plot\nplt.show() ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "as",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "True",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "0.25",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "2",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "4",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "6",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "8",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "10",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "12",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "14",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "16",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "for",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "in",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Create bagging classifier",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Fit the model",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Append the model and score to their respective list",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Generate the plot of scores against number of estimators",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "9",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "6",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Adjust labels and font (to make visable)",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          },
          {
            "text": "\"n_estimators\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          },
          {
            "text": "18",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\"score\"",
            "color": "rgb(0, 128, 0)",
            "class": "pythonstringcolor"
          },
          {
            "text": "18",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "16",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "# Visualize plot",
            "color": "rgb(112, 128, 144)",
            "class": "commentcolor"
          }
        ],
        "classList": [
          "w3-code",
          "notranslate",
          "pythonHigh"
        ],
        "isNotranslate": true
      },
      "images": [
        {
          "src": "img_ml_bagging2.png",
          "alt": "",
          "title": "",
          "local_path": "/home/ziko/Dev/Scraper/assets/python/img_ml_bagging2.png"
        }
      ],
      "code": "import matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nestimator_range = [2,4,6,8,10,12,14,16]\n\nmodels = []\nscores = []\n\nfor n_estimators in estimator_range:\n\n# Create bagging classifier\nclf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n\n# Fit the model\nclf.fit(X_train, y_train)\n\n# Append the model and score to their respective list\nmodels.append(clf)\nscores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))\n\n# Generate the plot of scores against number of estimators\nplt.figure(figsize=(9,6))\nplt.plot(estimator_range, scores)\n\n# Adjust labels and font (to make visable)\nplt.xlabel(\"n_estimators\", fontsize = 18)\nplt.ylabel(\"score\", fontsize = 18)\nplt.tick_params(labelsize = 16)\n\n# Visualize plot\nplt.show()",
      "syntax_highlighting": [
        {
          "text": "\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nestimator_range = [2,4,6,8,10,12,14,16]\n\nmodels = []\nscores = []\n\nfor n_estimators in estimator_range:\n \n\u00a0\u00a0\u00a0\u00a0# Create bagging classifier\n\u00a0\u00a0\u00a0\u00a0clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n \n\u00a0\u00a0\u00a0\u00a0# Fit the model\n\u00a0\u00a0\u00a0\u00a0clf.fit(X_train, y_train)\n \n\u00a0\u00a0\u00a0\u00a0# Append the model and score to their respective list\n\u00a0\u00a0\u00a0\u00a0models.append(clf)\n\u00a0\u00a0\u00a0\u00a0scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))\n \n# Generate the plot of scores against number of estimators\nplt.figure(figsize=(9,6))\nplt.plot(estimator_range, scores)\n\n# Adjust labels and font (to make visable)\nplt.xlabel(\"n_estimators\", fontsize = 18)\nplt.ylabel(\"score\", fontsize = 18)\nplt.tick_params(labelsize = 16)\n\n# Visualize plot\nplt.show() ",
          "color": "black",
          "class": [
            "pythoncolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "as",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "True",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "0.25",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "2",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "4",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "6",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "8",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "10",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "12",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "14",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "16",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "for",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "in",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "# Create bagging classifier",
          "color": "slategray",
          "class": [
            "commentcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "# Fit the model",
          "color": "slategray",
          "class": [
            "commentcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "# Append the model and score to their respective list",
          "color": "slategray",
          "class": [
            "commentcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "# Generate the plot of scores against number of estimators",
          "color": "slategray",
          "class": [
            "commentcolor"
          ]
        },
        {
          "text": "9",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "6",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "# Adjust labels and font (to make visable)",
          "color": "slategray",
          "class": [
            "commentcolor"
          ]
        },
        {
          "text": "\"n_estimators\"",
          "color": "green",
          "class": [
            "pythonstringcolor"
          ]
        },
        {
          "text": "18",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\"score\"",
          "color": "green",
          "class": [
            "pythonstringcolor"
          ]
        },
        {
          "text": "18",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "16",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "# Visualize plot",
          "color": "slategray",
          "class": [
            "commentcolor"
          ]
        }
      ],
      "language": "html",
      "code_html": "<div class=\"w3-code notranslate pythonHigh\"><span class=\"pythoncolor\" style=\"color:black\">\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> matplotlib.pyplot <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">as</span> plt<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> datasets<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.model_selection <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> train_test_split<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.metrics <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> accuracy_score<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.ensemble <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> BaggingClassifier<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\ndata = datasets.load_wine(as_frame = <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">True</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX = data.data<br/>\ny = data.target<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class=\"pythonnumbercolor\" style=\"color:#905\">0.25</span>, random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nestimator_range = [<span class=\"pythonnumbercolor\" style=\"color:#905\">2</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">4</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">6</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">8</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">10</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">12</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">14</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">16</span>]<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nmodels = []<br/>\nscores = []<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">for</span> n_estimators <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">in</span> estimator_range:<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span> <br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span>\u00a0\u00a0\u00a0\u00a0<span class=\"commentcolor\" style=\"color:slategray\"># Create bagging classifier<br/></span><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span>\u00a0\u00a0\u00a0\u00a0clf = BaggingClassifier(n_estimators = n_estimators, random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span> <br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span>\u00a0\u00a0\u00a0\u00a0<span class=\"commentcolor\" style=\"color:slategray\"># Fit the model<br/></span><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span>\u00a0\u00a0\u00a0\u00a0clf.fit(X_train, y_train)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span> <br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span>\u00a0\u00a0\u00a0\u00a0<span class=\"commentcolor\" style=\"color:slategray\"># Append the model and score to their respective list<br/></span><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span>\u00a0\u00a0\u00a0\u00a0models.append(clf)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span>\u00a0\u00a0\u00a0\u00a0scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span> <br/>\n<span class=\"commentcolor\" style=\"color:slategray\"># Generate the plot of scores against number of estimators<br/></span>\nplt.figure(figsize=(<span class=\"pythonnumbercolor\" style=\"color:#905\">9</span>,<span class=\"pythonnumbercolor\" style=\"color:#905\">6</span>))<br/>\nplt.plot(estimator_range, scores)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\n<span class=\"commentcolor\" style=\"color:slategray\"># Adjust labels and font (to make visable)<br/></span>\nplt.xlabel(<span class=\"pythonstringcolor\" style=\"color:green\">\"n_estimators\"</span>, fontsize = <span class=\"pythonnumbercolor\" style=\"color:#905\">18</span>)<br/>\nplt.ylabel(<span class=\"pythonstringcolor\" style=\"color:green\">\"score\"</span>, fontsize = <span class=\"pythonnumbercolor\" style=\"color:#905\">18</span>)<br/>\nplt.tick_params(labelsize = <span class=\"pythonnumbercolor\" style=\"color:#905\">16</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\n<span class=\"commentcolor\" style=\"color:slategray\"># Visualize plot<br/></span>\nplt.show() </span></div>",
      "code_classes": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nestimator_range = [2,4,6,8,10,12,14,16]\n\nmodels = []\nscores = []\n\nfor n_estimators in estimator_range:\n    \n\u00a0\u00a0\u00a0\u00a0# Create bagging classifier\n\u00a0\u00a0\u00a0\u00a0clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n    \n\u00a0\u00a0\u00a0\u00a0# Fit the model\n\u00a0\u00a0\u00a0\u00a0clf.fit(X_train, y_train)\n    \n\u00a0\u00a0\u00a0\u00a0# Append the model and score to their respective list\n\u00a0\u00a0\u00a0\u00a0models.append(clf)\n\u00a0\u00a0\u00a0\u00a0scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))\n    \n# Generate the plot of scores against number of estimators\nplt.figure(figsize=(9,6))\nplt.plot(estimator_range, scores)\n\n# Adjust labels and font (to make visable)\nplt.xlabel(\"n_estimators\", fontsize = 18)\nplt.ylabel(\"score\", fontsize = 18)\nplt.tick_params(labelsize = 16)\n\n# Visualize plot\nplt.show() ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "as",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "True",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "0.25",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "2",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "4",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "6",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "8",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "10",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "12",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "14",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "16",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "for",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "in",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Create bagging classifier",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Fit the model",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Append the model and score to their respective list",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Generate the plot of scores against number of estimators",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "9",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "6",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Adjust labels and font (to make visable)",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        },
        {
          "text": "\"n_estimators\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        },
        {
          "text": "18",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\"score\"",
          "color": "rgb(0, 128, 0)",
          "class": "pythonstringcolor"
        },
        {
          "text": "18",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "16",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "# Visualize plot",
          "color": "rgb(112, 128, 144)",
          "class": "commentcolor"
        }
      ],
      "class_list": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "is_notranslate": true
    },
    {
      "type": "header",
      "metadata": {
        "level": "h2"
      },
      "text": "Results Explained",
      "level": "h2"
    },
    {
      "type": "text",
      "metadata": {},
      "links": [
        {
          "text": "cross validation",
          "href": "https://www.w3schools.com/python_ml_cross_validation.asp",
          "title": ""
        }
      ],
      "text": "By iterating through different values for the number of estimators we can see an increase in model performance from 82.2% to 95.5%. After 14 estimators the accuracy begins to drop, again if you set a different random_state the values you see will vary. That is why it is best practice to use cross validation to ensure stable results.",
      "html": "<p>By iterating through different values for the number of estimators we can see an increase in model performance from 82.2% to 95.5%. After 14 estimators the accuracy begins to drop, again if you set a different <code>random_state</code> the values you see will vary.\nThat is why it is best practice to use <a href=\"python_ml_cross_validation.asp\">cross validation</a> to ensure stable results.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "In this case, we see a 13.3% increase in accuracy when it comes to identifying the type of the wine.",
      "html": "<p>In this case, we see a 13.3% increase in accuracy when it comes to identifying the type of the wine.</p>"
    },
    {
      "type": "header",
      "metadata": {
        "level": "h2"
      },
      "text": "Another Form of Evaluation",
      "level": "h2"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "As bootstrapping chooses random subsets of observations to create classifiers, there are observations that are left out in the selection process. These \"out-of-bag\" observations can then be used to evaluate the model, similarly to that of a test set. Keep in mind, that out-of-bag estimation can overestimate error in binary classification problems and should only be used as a compliment to other metrics.",
      "html": "<p>As bootstrapping chooses random subsets of observations to create classifiers, there are observations that are left out in the selection process. These \"out-of-bag\" observations can then be used to evaluate the model, similarly to that of a test set. Keep in mind, that out-of-bag estimation can overestimate error in binary classification problems and should only be used as a compliment to other metrics.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "We saw in the last exercise that 12 estimators yielded the highest accuracy, so we will use that to create our model. This time setting the parameter oob_score to true to evaluate the model with out-of-bag score.",
      "html": "<p>We saw in the last exercise that 12 estimators yielded the highest accuracy, so we will use that to create our model. This time setting the parameter <code>oob_score</code> to true to evaluate the model with out-of-bag score.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "python",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\noob_model = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\noob_model.fit(X_train, y_train)\n\nprint(oob_model.oob_score_)\n ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "True",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "0.25",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "12",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "True",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "print",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-code",
          "notranslate",
          "pythonHigh"
        ],
        "isNotranslate": true
      },
      "code": "from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\noob_model = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\noob_model.fit(X_train, y_train)\n\nprint(oob_model.oob_score_)",
      "syntax_highlighting": [
        {
          "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\noob_model = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\noob_model.fit(X_train, y_train)\n\nprint(oob_model.oob_score_)\n ",
          "color": "black",
          "class": [
            "pythoncolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "True",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "0.25",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "12",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "True",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "print",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        }
      ],
      "language": "html",
      "code_html": "<div class=\"w3-code notranslate pythonHigh\"><span class=\"pythoncolor\" style=\"color:black\">\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> datasets<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.model_selection <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> train_test_split<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.ensemble <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> BaggingClassifier<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\ndata = datasets.load_wine(as_frame = <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">True</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX = data.data<br/>\ny = data.target<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class=\"pythonnumbercolor\" style=\"color:#905\">0.25</span>, random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\noob_model = BaggingClassifier(n_estimators = <span class=\"pythonnumbercolor\" style=\"color:#905\">12</span>, oob_score = <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">True</span>,random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\noob_model.fit(X_train, y_train)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">print</span>(oob_model.oob_score_)<span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span> </span></div>",
      "code_classes": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\n\ndata = datasets.load_wine(as_frame = True)\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\noob_model = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\noob_model.fit(X_train, y_train)\n\nprint(oob_model.oob_score_)\n ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "True",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "0.25",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "12",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "True",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "print",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "is_notranslate": true
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Since the samples used in OOB and the test set are different, and the dataset is relatively small, there is a difference in the accuracy. It is rare that they would be exactly the same, again OOB should be used quick means for estimating error, but is not the only evaluation metric.",
      "html": "<p>Since the samples used in OOB and the test set are different, and the dataset is relatively small, there is a difference in the accuracy. It is rare that they would be exactly the same, again OOB should be used quick means for estimating error, but is not the only evaluation metric.</p>"
    },
    {
      "type": "header",
      "metadata": {
        "level": "h2"
      },
      "text": "Generating Decision Trees from Bagging Classifier",
      "level": "h2"
    },
    {
      "type": "text",
      "metadata": {},
      "links": [
        {
          "text": "Decision Tree",
          "href": "https://www.w3schools.com/python_ml_decision_tree.asp",
          "title": ""
        }
      ],
      "text": "As was seen in the Decision Tree lesson, it is possible to graph the decision tree the model created. It is also possible to see the individual decision trees that went into the aggregated classifier. This helps us to gain a more intuitive understanding on how the bagging model arrives at its predictions.",
      "html": "<p>As was seen in the <a href=\"python_ml_decision_tree.asp\">Decision Tree</a> lesson, it is possible to graph the decision tree the model created. It is also possible to see the individual decision trees that went into the aggregated classifier. This helps us to gain a more intuitive understanding on how the bagging model arrives at its predictions.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Note: This is only functional with smaller datasets, where the trees are relatively shallow and narrow making them easy to visualize.",
      "html": "<p>Note: This is only functional with smaller datasets, where the trees are relatively shallow and narrow making them easy to visualize.</p>"
    },
    {
      "type": "text",
      "metadata": {},
      "text": "We will need to import plot_tree function from sklearn.tree . The different trees can be graphed by changing the estimator you wish to visualize.",
      "html": "<p>We will need to import <code>plot_tree</code> function from <code>sklearn.tree</code>. The different trees can be graphed by changing the estimator you wish to visualize.</p>"
    },
    {
      "type": "code",
      "metadata": {
        "language": "python",
        "tryItLink": null,
        "syntaxHighlighting": [
          {
            "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import plot_tree\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nclf = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\nclf.fit(X_train, y_train)\n\nplt.figure(figsize=(30, 20))\n\nplot_tree(clf.estimators_[0], feature_names = X.columns) ",
            "color": "rgb(0, 0, 0)",
            "class": "pythoncolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "from",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "import",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "0.25",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "12",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "True",
            "color": "rgb(0, 92, 197)",
            "class": "pythonkeywordcolor"
          },
          {
            "text": "22",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "30",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "20",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "\n",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          },
          {
            "text": "0",
            "color": "rgb(153, 0, 85)",
            "class": "pythonnumbercolor"
          }
        ],
        "classList": [
          "w3-code",
          "notranslate",
          "pythonHigh"
        ],
        "isNotranslate": true
      },
      "images": [
        {
          "src": "img_ml_bagging4.png",
          "alt": "",
          "title": "",
          "local_path": "/home/ziko/Dev/Scraper/assets/python/img_ml_bagging4.png"
        }
      ],
      "code": "from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import plot_tree\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nclf = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\nclf.fit(X_train, y_train)\n\nplt.figure(figsize=(30, 20))\n\nplot_tree(clf.estimators_[0], feature_names = X.columns)",
      "syntax_highlighting": [
        {
          "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import plot_tree\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nclf = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\nclf.fit(X_train, y_train)\n\nplt.figure(figsize=(30, 20))\n\nplot_tree(clf.estimators_[0], feature_names = X.columns) ",
          "color": "black",
          "class": [
            "pythoncolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "from",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "import",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "0.25",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "12",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "True",
          "color": "#005cc5",
          "class": [
            "pythonkeywordcolor"
          ]
        },
        {
          "text": "22",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "30",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "20",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "\n",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        },
        {
          "text": "0",
          "color": "#905",
          "class": [
            "pythonnumbercolor"
          ]
        }
      ],
      "language": "html",
      "code_html": "<div class=\"w3-code notranslate pythonHigh\"><span class=\"pythoncolor\" style=\"color:black\">\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> datasets<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.model_selection <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> train_test_split<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.ensemble <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> BaggingClassifier<br/>\n<span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">from</span> sklearn.tree <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">import</span> plot_tree<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX = data.data<br/>\ny = data.target<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class=\"pythonnumbercolor\" style=\"color:#905\">0.25</span>, random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nclf = BaggingClassifier(n_estimators = <span class=\"pythonnumbercolor\" style=\"color:#905\">12</span>, oob_score = <span class=\"pythonkeywordcolor\" style=\"color:#005cc5\">True</span>,random_state = <span class=\"pythonnumbercolor\" style=\"color:#905\">22</span>)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nclf.fit(X_train, y_train)<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nplt.figure(figsize=(<span class=\"pythonnumbercolor\" style=\"color:#905\">30</span>, <span class=\"pythonnumbercolor\" style=\"color:#905\">20</span>))<br/><span class=\"pythonnumbercolor\" style=\"color:#905\">\n</span><br/>\nplot_tree(clf.estimators_[<span class=\"pythonnumbercolor\" style=\"color:#905\">0</span>], feature_names = X.columns) </span></div>",
      "code_classes": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "tryItLink": null,
      "syntax_highlighting_data": [
        {
          "text": "\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import plot_tree\n\nX = data.data\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n\nclf = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)\n\nclf.fit(X_train, y_train)\n\nplt.figure(figsize=(30, 20))\n\nplot_tree(clf.estimators_[0], feature_names = X.columns) ",
          "color": "rgb(0, 0, 0)",
          "class": "pythoncolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "from",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "import",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "0.25",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "12",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "True",
          "color": "rgb(0, 92, 197)",
          "class": "pythonkeywordcolor"
        },
        {
          "text": "22",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "30",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "20",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "\n",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        },
        {
          "text": "0",
          "color": "rgb(153, 0, 85)",
          "class": "pythonnumbercolor"
        }
      ],
      "class_list": [
        "w3-code",
        "notranslate",
        "pythonHigh"
      ],
      "is_notranslate": true
    },
    {
      "type": "text",
      "metadata": {},
      "text": "Here we can see just the first decision tree that was used to vote on the final prediction. Again, by changing the index of the classifier you can see each of the trees that have been aggregated.",
      "html": "<p>Here we can see just the first decision tree that was used to vote on the final prediction. Again, by changing the index of the classifier you can see each of the trees that have been aggregated.</p>"
    }
  ]
}