{
  "id": "6fe3a8a8-d924-4015-8d47-05fce46fab60",
  "title": "Perceptrons",
  "slug": "perceptrons",
  "metadata": {
    "description": "Learn about Perceptrons with clear explanations and practical examples.",
    "keywords": [
      "c",
      "perceptron",
      "weights",
      "input",
      "inputs",
      "output",
      "value",
      "neural",
      "threshold",
      "perceptrons",
      "networks"
    ],
    "difficulty": "intermediate",
    "prerequisites": [
      "C Basics"
    ],
    "estimated_time": 5,
    "category": "LearnAI",
    "subcategory": "ML Perceptrons"
  },
  "content_sections": [
    {
      "type": "introduction",
      "title": "Introduction",
      "content": "Perceptrons",
      "order": 1,
      "code": null,
      "language": null,
      "explanation": null
    },
    {
      "type": "concept",
      "title": "Details",
      "content": "A\nPerceptron\nis an\nArtificial Neuron\n.\nIt is the simplest possible\nNeural Network\n.\nNeural Networks\nare the building blocks of\nMachine Learning\n.\nFrank Rosenblatt\nFrank Rosenblatt\n(1928 \u2013 1971) was an American psychologist\nnotable in the field of Artificial Intelligence.\nIn\n1957\nhe started something really big. He \"invented\" a\nPerceptron\nprogram,\non an IBM 704 computer at Cornell Aeronautical Laboratory.\nScientists had discovered that brain cells (\nNeurons\n)\nreceive input from our senses by electrical signals.\nThe Neurons, then again, use electrical signals to store information, and to make decisions based on \nFrank had the idea that\nPerceptrons\ncould simulate brain principles, with the ability to learn and make decisions.\nThe Perceptron\nThe original\nPerceptron\nwas designed to take a number of\nbinary\ninputs, and produce one\nbinary\noutput (0 or 1).\nThe idea was to use different\nweights\nto represent the importance of each\ninput\n,\nand that the sum of the values should be greater than a\nthreshold\nvalue before making a \ndecision like\nyes\nor\nno\n(true or false) (0 or 1).\nPerceptron Example\nImagine a perceptron (in your brain).\nThe perceptron tries to decide if you should go to a concert.\nIs the artist good? Is the weather good?\nWhat weights should these facts have?\nCriteria\nInput\nWeight\nArtists is Good\nx1\n= 0 or 1\nw1\n= 0.7\nWeather is Good\nx2\n= 0 or 1\nw2\n= 0.6\nFriend will Come\nx3\n= 0 or 1\nw3\n= 0.5\nFood is Served\nx4\n= 0 or 1\nw4\n= 0.3\nAlcohol is Served\nx5\n= 0 or 1\nw5\n= 0.4\nThe Perceptron Algorithm\nFrank Rosenblatt suggested this algorithm:\nSet a threshold value\nMultiply all inputs with its weights\nSum all the results\nActivate the output\n1. Set a threshold value\n:\nThreshold = 1.5\n2. Multiply all inputs with its weights\n:\nx1 * w1 = 1 * 0.7 = 0.7\nx2 * w2 = 0 * 0.6 = 0\nx3 * w3 = 1 * 0.5 = 0.5\nx4 * w4 = 0 * 0.3 = 0\nx5 * w5 = 1 * 0.4 = 0.4\n3. Sum all the results\n:\n0.7 + 0 + 0.5 + 0 + 0.4 = 1.6 (The Weighted Sum)\n4. Activate the Output\n:\nReturn true if the sum > 1.5 (\"Yes I will go to the Concert\")\nNote\nIf the weather weight is 0.6 for you, it might be different for someone else.\nA higher weight means that the weather is more important to them.\nIf the threshold value is 1.5 for you, it might be different for someone else.\nA lower threshold means they are more wanting to go to any concert.\nExample\nconst threshold = 1.5;\nconst inputs = [1, 0, 1, 0, 1];\nconst weights = [0.7, 0.6, 0.5, 0.3, 0.4];\nlet sum = 0;\nfor (let i = 0; i < inputs.length; i++) {\nsum += inputs[i] * weights[i];\n}\nconst activate = (sum > 1.5);\n\nPerceptron in AI\nA\nPerceptron\nis an\nArtificial Neuron\n.\nIt is inspired by the function of a\nBiological Neuron\n.\nIt plays a crucial role in\nArtificial Intelligence\n.\nIt is an important building block in\nNeural Networks\n.\nTo understand the theory behind it, we can break down its components:\nPerceptron Inputs (nodes)\nNode values (1, 0, 1, 0, 1)\nNode Weights (0.7, 0.6, 0.5, 0.3, 0.4)\nSummation\nTreshold Value\nActivation Function\nSummation (sum > treshold)\n1. Perceptron Inputs\nA perceptron receives one or more input.\nPerceptron inputs are called\nnodes\n.\nThe nodes have both a\nvalue\nand a\nweight\n.\n2. Node Values (Input Values)\nInput nodes have a binary value of\n1\nor\n0\n.\nThis can be interpreted as\ntrue\nor\nfalse\n/\nyes\nor\nno\n.\nThe values are:\n1, 0, 1, 0, 1\n3. Node Weights\nWeights are values assigned to each input.\nWeights shows the\nstrength\nof each node.\nA higher value means that the input has a stronger influence on the output.\nThe weights are:\n0.7, 0.6, 0.5, 0.3, 0.4\n4. Summation\nThe perceptron calculates the weighted sum of its inputs.\nIt multiplies each input by its corresponding weight and sums up the results.\nThe sum is:\n0.7*1 + 0.6*0 + 0.5*1 + 0.3*0 + 0.4*1 = 1.6\n6. The Threshold\nThe Threshold is the value needed for the perceptron to fire (outputs 1),\notherwise it remains inactive (outputs 0).\nIn the example, the treshold value is:\n1.5\n5. The Activation Function\nAfter the summation, the perceptron applies the activation function.\nThe purpose is to introduce non-linearity into the output.\nIt determines whether the perceptron should fire or not based on the aggregated input.\nThe activation function is simple:\n(sum > treshold) == (1.6 > 1.5)\nThe Output\nThe final output of the perceptron is the result of the activation function.\nIt represents the perceptron's decision or prediction based on the input and the weights.\nThe activation function maps the the weighted sum into a binary value.\nThe binary\n1\nor\n0\ncan be interpreted as\ntrue\nor\nfalse\n/\nyes\nor\nno\n.\nThe output is\n1\nbecause:\n(sum > treshold) == true\n.\nPerceptron Learning\nThe perceptron can learn from examples through a process called training.\nDuring training, the perceptron adjusts its weights based on observed errors.\nThis is typically done using a learning algorithm such as the perceptron learning rule or a backpropagation algorithm.\nThe learning process presents the perceptron with labeled examples, where the desired output is known.\nThe perceptron compares its output with the desired output and adjusts its weights accordingly,\naiming to minimize the error between the predicted and desired outputs.\nThe learning process allows the perceptron to learn the weights that enable it\nto make accurate predictions for new, unknown inputs.\nNote\nIt is obvious a decisions can NOT be made by\nOne Neuron\nalone.\nOther neurons must provide more input:\nIs the artist good\nIs the weather good\n...\nMulti-Layer Perceptrons\ncan be used for more sophisticated decision making.\nIt's important to note that while perceptrons were influential in the development of artificial neural networks,\nthey are limited to learning linearly separable patterns.\nHowever, by stacking multiple perceptrons together in layers and incorporating non-linear activation functions,\nneural networks can overcome this limitation and learn more complex patterns.\nNeural Networks\nThe\nPerceptron\ndefines the first step into\nNeural Networks\n:\nPerceptrons are often used as the building blocks for more complex neural networks, such as multi-layer perceptrons\n(MLPs) or deep neural networks (DNNs).\nBy combining multiple perceptrons in layers and connecting them in a\nnetwork structure, these models can learn and represent complex patterns and relationships in data,\nenabling tasks such as image recognition, natural language processing, and decision making.\n\n\u2605\n+1",
      "order": 2,
      "code": null,
      "language": null,
      "explanation": null
    },
    {
      "type": "code_example",
      "title": "Example",
      "content": "",
      "order": 3,
      "code": "const threshold = 1.5;\nconst inputs = [1, 0, 1, 0, 1];\nconst weights = [0.7, 0.6, 0.5, 0.3, 0.4];\nlet sum = 0;\nfor (let i = 0; i < inputs.length; i++) {\nsum += inputs[i] * weights[i];\n}\nconst activate = (sum > 1.5);",
      "language": "javascript",
      "explanation": "Example of example"
    }
  ],
  "practice_exercises": [
    {
      "title": "Complete the Code 1",
      "description": "Fill in the missing line to make this code work.",
      "difficulty": "medium",
      "starter_code": "const threshold = 1.5;\nconst inputs = [1, 0, 1, 0, 1];\nconst weights = [0.7, 0.6, 0.5, 0.3, 0.4];\nlet sum = 0;\nfor (let i = 0; i < inputs.length; i++) {\nsum += inputs[i] * weights[i];\n}\n# TODO: Complete this line",
      "solution": "const threshold = 1.5;\nconst inputs = [1, 0, 1, 0, 1];\nconst weights = [0.7, 0.6, 0.5, 0.3, 0.4];\nlet sum = 0;\nfor (let i = 0; i < inputs.length; i++) {\nsum += inputs[i] * weights[i];\n}\nconst activate = (sum > 1.5);"
    },
    {
      "title": "Practice Exercise",
      "description": "Create an example that applies the concepts from this tutorial.",
      "difficulty": "medium",
      "starter_code": "# Add your code here",
      "solution": "# Example solution would go here"
    }
  ],
  "related_topics": [
    {
      "id": "1c0d9415-82ae-447c-b94e-125f1ebb938d",
      "title": "C Best Practices",
      "relationship": "related_topic"
    },
    {
      "id": "1a928917-d1ed-4842-9818-33b7f0678807",
      "title": "C Common Pitfalls and How to Avoid Them",
      "relationship": "suggested_reading"
    },
    {
      "id": "99b511eb-0256-469b-a3d2-aff40b5688ab",
      "title": "C Fundamentals",
      "relationship": "prerequisite"
    }
  ],
  "quiz": [
    {
      "question": "What is Perceptrons\n\nA\nPerceptron?",
      "options": [
        "None of the above.",
        "None of the above.",
        "an\nArtificial Neuron",
        "the simplest possible\nNeural Network"
      ],
      "correct_answer": 2,
      "explanation": "The correct definition of Perceptrons\n\nA\nPerceptron is 'an\nArtificial Neuron'."
    },
    {
      "question": "What is It?",
      "options": [
        "an\nArtificial Neuron",
        "None of the above.",
        "the simplest possible\nNeural Network",
        "None of the above."
      ],
      "correct_answer": 2,
      "explanation": "The correct definition of It is 'the simplest possible\nNeural Network'."
    }
  ],
  "summary": "This tutorial covers Perceptrons concepts and techniques. You'll learn how to use Perceptrons effectively, including key principles, common patterns, and practical examples. By the end of this tutorial, you'll have a solid understanding of Perceptrons and how to apply it in your projects."
}