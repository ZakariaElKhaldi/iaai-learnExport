{
  "id": "aecac3c6-6dad-49c4-8098-eebc0940f749",
  "title": "Machine Learning - K-means",
  "slug": "machine-learning-k-means",
  "metadata": {
    "description": "Learn about Machine Learning - K-means with clear explanations and practical examples.",
    "keywords": [
      "c",
      "data",
      "kmeans",
      "clusters",
      "means",
      "method",
      "elbow",
      "example",
      "result",
      "points",
      "cluster"
    ],
    "difficulty": "beginner",
    "prerequisites": [
      "C Basics"
    ],
    "estimated_time": 5,
    "category": "LearnMatplotlib",
    "subcategory": "K-means"
  },
  "content_sections": [
    {
      "type": "introduction",
      "title": "Introduction",
      "content": "Machine Learning - K-means",
      "order": 1,
      "code": null,
      "language": null,
      "explanation": null
    },
    {
      "type": "concept",
      "title": "Details",
      "content": "On this page, .com collaborates with\nNYC Data Science Academy\n, to deliver digital training content to our students.\nK-means\nK-means is an unsupervised learning method for clustering data points. The algorithm iteratively divides data points into K clusters by minimizing the variance in each cluster.\nHere, we will show you how to estimate the best value for K using the elbow method, then use K-means clustering to group the data points into clusters.\nHow does it work?\nFirst, each data point is randomly assigned to one of the K clusters. Then, we compute the centroid (functionally the center) of each cluster, and reassign each data point to the cluster with the closest centroid. We repeat this process until the cluster assignments for each data point are no longer changing.\nK-means clustering requires us to select K, the number of clusters we want to group the data into. The elbow method lets us graph the inertia (a distance-based metric) and visualize the point at which it starts decreasing linearly. This point is referred to as the \"elbow\" and is a good estimate for the best value for K based on our data.\nExample\nStart by visualizing some data points:\nimport matplotlib.pyplot as plt\nx = [4, 5, 10, 4, \n  3, 11, 14 , 6, 10, 12]\ny = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]\nplt.scatter(x, y)\nplt.show()\nResult\nRun example \u00bb\nADVERTISEMENT\nNow we utilize the elbow method to visualize the intertia for different values of K:\nExample\nfrom sklearn.cluster import KMeans\ndata = list(zip(x, y))\ninertias = []\nfor i in range(1,11):\nkmeans = KMeans(n_clusters=i)\nkmeans.fit(data)\ninertias.append(kmeans.inertia_)\nplt.plot(range(1,11), inertias, marker='o')\nplt.title('Elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()\nResult\nRun example \u00bb\nThe elbow method shows that 2 is a good value for K, so we retrain and visualize the result:\nExample\nkmeans = KMeans(n_clusters=2)\nkmeans.fit(data)\nplt.scatter(x, y, c=kmeans.labels_)\nplt.show()\nResult\nRun example \u00bb\nExample Explained\nImport the modules you need.\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nYou can learn about the Matplotlib module in our\n\"Matplotlib Tutorial\n.\nscikit-learn is a popular library for machine learning.\nCreate arrays that resemble two variables in a dataset. Note that while we only use two variables here, this method will work with any number of variables:\nx = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]\ny = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]\nTurn the data into a set of points:\ndata = list(zip(x, y))\nprint(data)\nResult:\n[(4, 21), (5, 19), (10, 24), (4, 17), (3, 16), (11, 25), (14, 24), (6, 22), (10, 21), (12, 21)]\nIn order to find the best value for K, we need to run K-means across our data for a range of possible values. We only have 10 data points, so the maximum number of clusters is 10. So for each value K in range(1,11), we train a K-means model and plot the intertia at that number of clusters:\ninertias = []\nfor i in range(1,11):\nkmeans = KMeans(n_clusters=i)\nkmeans.fit(data)\ninertias.append(kmeans.inertia_)\nplt.plot(range(1,11), inertias, marker='o')\nplt.title('Elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()\nResult:\nWe can see that the \"elbow\" on the graph above (where the interia becomes more linear) is at K=2. We can then fit our K-means algorithm one more time and plot the different clusters assigned to the data:\nkmeans = KMeans(n_clusters=2)\nkmeans.fit(data)\nplt.scatter(x, y, c=kmeans.labels_)\nplt.show()\nResult:\n\n\u2605\n+1",
      "order": 2,
      "code": null,
      "language": null,
      "explanation": null
    },
    {
      "type": "code_example",
      "title": "Example",
      "content": "",
      "order": 3,
      "code": "import matplotlib.pyplot as plt\nx = [4, 5, 10, 4, \n  3, 11, 14 , 6, 10, 12]\ny = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]\nplt.scatter(x, y)\nplt.show()",
      "language": "python",
      "explanation": "Example of example"
    },
    {
      "type": "code_example",
      "title": "Example",
      "content": "",
      "order": 4,
      "code": "from sklearn.cluster import KMeans\ndata = list(zip(x, y))\ninertias = []\nfor i in range(1,11):\nkmeans = KMeans(n_clusters=i)\nkmeans.fit(data)\ninertias.append(kmeans.inertia_)\nplt.plot(range(1,11), inertias, marker='o')\nplt.title('Elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()",
      "language": "python",
      "explanation": "Example of example"
    },
    {
      "type": "code_example",
      "title": "Example",
      "content": "",
      "order": 5,
      "code": "kmeans = KMeans(n_clusters=2)\nkmeans.fit(data)\nplt.scatter(x, y, c=kmeans.labels_)\nplt.show()",
      "language": "python",
      "explanation": "Example of example"
    }
  ],
  "practice_exercises": [
    {
      "title": "Complete the Code 1",
      "description": "Fill in the missing line to make this code work.",
      "difficulty": "medium",
      "starter_code": "import matplotlib.pyplot as plt\nx = [4, 5, 10, 4, \n  3, 11, 14 , 6, 10, 12]\ny = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]\nplt.scatter(x, y)\n# TODO: Complete this line",
      "solution": "import matplotlib.pyplot as plt\nx = [4, 5, 10, 4, \n  3, 11, 14 , 6, 10, 12]\ny = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]\nplt.scatter(x, y)\nplt.show()"
    },
    {
      "title": "Complete the Code 2",
      "description": "Fill in the missing line to make this code work.",
      "difficulty": "medium",
      "starter_code": "from sklearn.cluster import KMeans\ndata = list(zip(x, y))\ninertias = []\nfor i in range(1,11):\nkmeans = KMeans(n_clusters=i)\nkmeans.fit(data)\ninertias.append(kmeans.inertia_)\nplt.plot(range(1,11), inertias, marker='o')\n# TODO: Complete this line\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()",
      "solution": "from sklearn.cluster import KMeans\ndata = list(zip(x, y))\ninertias = []\nfor i in range(1,11):\nkmeans = KMeans(n_clusters=i)\nkmeans.fit(data)\ninertias.append(kmeans.inertia_)\nplt.plot(range(1,11), inertias, marker='o')\nplt.title('Elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()"
    }
  ],
  "related_topics": [
    {
      "id": "8d94083f-8547-4152-a992-c0e794540402",
      "title": "C Best Practices",
      "relationship": "related_topic"
    },
    {
      "id": "189c418d-53af-4d46-a197-7fe72b45e4f1",
      "title": "C Common Pitfalls and How to Avoid Them",
      "relationship": "suggested_reading"
    },
    {
      "id": "137a7ba5-71ea-4fb0-9a6f-e39a365aae0d",
      "title": "C Fundamentals",
      "relationship": "prerequisite"
    }
  ],
  "quiz": [
    {
      "question": "What is means?",
      "options": [
        "Not a means.",
        "an unsupervised learning method for clustering data points",
        "None of the above.",
        "None of the above."
      ],
      "correct_answer": 1,
      "explanation": "The correct definition of means is 'an unsupervised learning method for clustering data points'."
    },
    {
      "question": "Which best describes the main purpose of this c feature?",
      "options": [
        "To organize and structure code",
        "To improve code readability",
        "To enhance performance",
        "All of the above"
      ],
      "correct_answer": 3,
      "explanation": "This feature serves multiple purposes in software development."
    }
  ],
  "summary": "This tutorial covers Machine Learning - K-means concepts and techniques. You'll learn how to use Machine Learning - K-means effectively, including key principles, common patterns, and practical examples. By the end of this tutorial, you'll have a solid understanding of Machine Learning - K-means and how to apply it in your projects."
}