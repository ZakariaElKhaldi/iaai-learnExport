{
  "id": "6c3e2f13-9e42-45bc-a4ab-10754f7681aa",
  "title": "DSACounting Sort Time Complexity",
  "slug": "dsacounting-sort-time-complexity",
  "metadata": {
    "description": "Learn about DSACounting Sort Time Complexity with clear explanations and practical examples.",
    "keywords": [
      "counting",
      "values",
      "sort",
      "time",
      "range",
      "complexity",
      "operations",
      "array",
      "cdot",
      "case"
    ],
    "difficulty": "intermediate",
    "prerequisites": [
      "C Basics"
    ],
    "estimated_time": 5,
    "category": "LearnDSA",
    "subcategory": "Counting Sort"
  },
  "content_sections": [
    {
      "type": "introduction",
      "title": "Introduction",
      "content": "DSA\nCounting Sort Time Complexity",
      "order": 1,
      "code": null,
      "language": null,
      "explanation": null
    },
    {
      "type": "concept",
      "title": "Details",
      "content": "See\nthis page\nfor a general explanation of what time complexity is.\nCounting Sort Time Complexity\nCounting Sort\nworks by first counting the occurrence of different values, and then uses that to recreate the array in a sorted order.\nAs a rule of thumb, the Counting Sort algorithm runs fast  when the range of possible values \\(k\\) is smaller than the number of values \\(n\\).\nTo represent the time complexity with Big O notation we need to first count the number of operations the algorithm does:\nFinding the maximum value: Every value must be evaluated once to find out if it is the maximum value, so \\(n\\) operations are needed.\nInitializing the counting array: With \\(k\\) as the maximum value in the array, we need \\(k+1\\) elements in the counting array to include 0. Every element in the counting array must be initialized, so \\(k+1\\) operations are needed.\nEvery value we want to sort is counted once, then removed, so 2 operations per count, \\(2 \\cdot n\\) operations in total.\nBuilding the sorted array: Create \\(n\\) elements in the sorted array: \\(n\\) operations.\nIn total we get:\n\\[\n\\begin{equation}\n\\begin{aligned}\nOperations {} & = n + (k+1) + (2 \\cdot n) + n \\\\\n           & = 4 \\cdot n + k + 1 \\\\\n           & \\approx 4 \\cdot n + k\n\\end{aligned}\n\\end{equation}\n\\]\nBased on what have seen about time complexity earlier, we can create a simplified expression using Big O notiation to represent time complexity:\n\\[\n\\begin{equation}\n\\begin{aligned}\nO(4 \\cdot n + k) {} & = O(4 \\cdot n) + O(k) \\\\\n           & = O(n) + O(k) \\\\\n           & = \\underline{\\underline{O(n+k)}}\n\\end{aligned}\n\\end{equation}\n\\]\nIt has already been mentioned that Counting Sort is effective when the range of different values \\(k\\) is relatively small compared to the total number of values to be sorted \\(n\\). We can now see this directly from the Big O expression \\(O(n+k)\\).\nJust imagine for example that the range of different numbers \\(k\\) is 10 times as large as the number of the values to be sorted. In such a case we can see that the algorithm uses most of its time on handling the range of different numbers \\(k\\), although the actual number of values to be sorted \\(n\\) is small in comparison.\nIt is not straight forward to show the time complexity for Counting Sort in a graph, or to have a simulation for the time complexity as we have had for the \nBelow is a plot that shows how much the time complexity for Counting Sort can vary, followed by an explanation for the best and worst case scenarios.\nThe\nbest case\nscenario for Counting Sort would be to have the range \\(k\\) just a fraction of \\(n\\), let's say \\(k(n)=0.1 \\cdot n\\). As an example of this, for 100 values, the range would be from 0 to 10, or for 1000 values the range would be from 0 to 100. In this case we get time complexity \\(O(n+k)=O(n+0.1 \\cdot n) = O(1.1 \\cdot n)\\) which is simplified to \\(O(n)\\).\nThe\nworst case\nhowever would be if the range is a lot larger than the input. Let's say for an input of just 10 values the the range is between 0 and 100, or similarly, for an input of 1000 values, the range is between 0 and 1000000. In such a scenario, the growth of \\(k\\) is quadratic with respect to \\(n\\), like this: \\(k(n)=n^2\\), and we get time complexity \\(O(n+k)=O(n+n^2)\\) which is simplified to \\(O(n^2)\\). A case that is even worse than this could also be constructed, but this case is chosen because it is relatively easy to understand, and perhaps not that unrealistic either.\nAs you can see, it is important to consider the range of values compared to the number of values to be sorted before choosing Counting Sort as your algorithm. Also, as mentioned at the top of the page, keep in mind that Counting sort only works for non negative integer values.\nCounting Sort Simulation\nRun different simulations of Counting Sort to see how the number of operations falls between the worst case scenario \\(O(n^2)\\) (red line) and best case scenario \\(O(n)\\) (green line).\nSet values (n):\n{{ this.userX }}\nRange (k), from 0 to:\n{{ this.userK }}\nRandom\nDescending\nAscending\n10 Random\nOperations: {{ operations }}\n{{runBtnText}}\nClear\nAs mentioned \nIf we hold \\(n\\) and \\(k\\) fixed, the \"Random\", \"Descending\" and \"Ascending\" alternatives in the simulation above results in the same number of operations. This is because the same thing happens in all three cases: A counting array is set up, the numbers are counted, and the new sorted array is created.\n\n\u2605\n+1",
      "order": 2,
      "code": null,
      "language": null,
      "explanation": null
    }
  ],
  "practice_exercises": [
    {
      "title": "Practice Exercise",
      "description": "Create an example that applies the concepts from this tutorial.",
      "difficulty": "medium",
      "starter_code": "# Add your code here",
      "solution": "# Example solution would go here"
    }
  ],
  "related_topics": [
    {
      "id": "4a12bcf4-74fe-4069-aae6-833fb884d7d1",
      "title": "C Best Practices",
      "relationship": "related_topic"
    },
    {
      "id": "7813bb7d-9249-4b4b-a08b-f5234a52c8a8",
      "title": "C Common Pitfalls and How to Avoid Them",
      "relationship": "suggested_reading"
    },
    {
      "id": "f357def6-4eba-4ffd-96b3-5e83d8f48c54",
      "title": "C Fundamentals",
      "relationship": "prerequisite"
    }
  ],
  "quiz": [
    {
      "question": "Which best describes the main purpose of this c feature?",
      "options": [
        "To organize and structure code",
        "To improve code readability",
        "To enhance performance",
        "All of the above"
      ],
      "correct_answer": 3,
      "explanation": "This feature serves multiple purposes in software development."
    },
    {
      "question": "Which best describes the main purpose of this c feature?",
      "options": [
        "To organize and structure code",
        "To improve code readability",
        "To enhance performance",
        "All of the above"
      ],
      "correct_answer": 3,
      "explanation": "This feature serves multiple purposes in software development."
    }
  ],
  "summary": "This tutorial covers DSACounting Sort Time Complexity concepts and techniques. You'll learn how to use DSACounting Sort Time Complexity effectively, including key principles, common patterns, and practical examples. By the end of this tutorial, you'll have a solid understanding of DSACounting Sort Time Complexity and how to apply it in your projects."
}