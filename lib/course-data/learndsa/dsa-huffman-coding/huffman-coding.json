{
  "id": "98f96e31-589b-4336-925d-fc52b6c5157f",
  "title": "Huffman Coding",
  "slug": "huffman-coding",
  "metadata": {
    "description": "Learn about Huffman Coding with clear explanations and practical examples.",
    "keywords": [
      "huffman",
      "code",
      "node",
      "word",
      "codes",
      "data",
      "freq",
      "letter",
      "char",
      "nodes"
    ],
    "difficulty": "beginner",
    "prerequisites": [
      "C Basics"
    ],
    "estimated_time": 9,
    "category": "LearnDSA",
    "subcategory": "DSA Huffman Coding"
  },
  "content_sections": [
    {
      "type": "introduction",
      "title": "Introduction",
      "content": "Huffman Coding",
      "order": 1,
      "code": null,
      "language": null,
      "explanation": null
    },
    {
      "type": "concept",
      "title": "Details",
      "content": "Huffman Coding\nHuffman Coding is an algorithm used for lossless data compression.\nHuffman Coding is also used as a component in many different compression algorithms. It is used as a component in lossless compressions such as zip, gzip, and png, and even as part of lossy compression algorithms like mp3 and jpeg.\nUse the animation below to see how a text can be compressed using Huffman Coding.\nText:\n{{ el.letter }}\n{{btnText}}\n{{inpComment}}\nHuffman code:\n{{ el.code }}\nUTF-8:\n{{ el.code }}\n{{ huffmanBitCount }} bits\n{{ utf8BitCount }} bits\nResult\nThe Huffman code is {{compression}}% of the original size.\nThe animation shows how the letters in a text are normally stored using\nUTF-8\n, and how Huffman Coding makes it possible to store the same text with fewer bits.\nHow it works:\nCount how often each piece of data occurs.\nBuild a\nbinary tree\n, starting with the nodes with the lowest count. The new parent node has the combined count of its child nodes.\nThe edge from a parent gets '0' for the left child, and '1' for the edge to the right child.\nIn the finished binary tree, follow the edges from the root node, adding '0' or '1' for each branch, to find the new Huffman code for each piece of data.\nCreate the Huffman code by converting the data, piece-by-piece, into a binary code using the binary tree.\nHuffman Coding uses a variable length of bits to represent each piece of data, with a shorter bit representation for the pieces of data that occurs more often.\nFurthermore, Huffman Coding ensures that no code is the prefix of another code, which makes the compressed data easy to decode.\nData compression\nis when the original data size is reduced, but the information is mostly, or fully, kept. Sound or music files are for example usually stored in a compressed format, roughly just 10% of the original data size, but with most of the information kept.\nLossless\nmeans that even after the data is compressed, all the information is still there. This means that for example a compressed text still has all the same letters and characters as the original.\nLossy\nis the other variant of data compression, where some of the original information is lost, or sacrificed, so that the data can be compressed even more. Music, images, and video is normally stored and streamed with lossy compression like mp3, jpeg, and mp4.\nCreating A Huffman Code Manually\nTo get a better understanding of how Huffman Coding works, let's create a Huffman code manually, using the same text as in the animation: 'lossless'.\nA text is normally stored in the computer using\nUTF-8\n, which means that each letter is stored using 8 bits for normal latin letters, like we have in 'lossless'. Other letters or symbols such as '\u20ac' or '\ud83e\udd84' are stored using more bits.\nTo compress the text 'lossless' using Huffman Coding, we start by counting each letter.\n{{ line.label }}\n{{node.letter}}\n{{node.freq}}\nAs you can see in the nodes above, 's' occurs 4 times, 'l' occurs 2 times, and 'o' and 'e' occurs just 1 time each.\nWe start building the tree with the least occurring letters 'o' and 'e', and their parent node gets count '2', because the counts for letter 'o' and 'e' are summarized.\n{{ line.label }}\n{{node.letter}}\n{{node.freq}}\nThe \n{{ line.label }}\n{{node.letter}}\n{{node.freq}}\nNow, the last node 's' must be added to the binary tree. Letter node 's' and the parent node with count '4' get a new parent node with count '8'.\n{{ line.label }}\n{{node.letter}}\n{{node.freq}}\nFollowing the edges from the root node, we can now determine the Huffman code for each letter in the word 'lossless'.\n{{ line.label }}\n{{node.letter}}\n{{node.freq}}\nThe Huffman code for each letter can now be found under each letter node in the image above. A good thing about Huffman coding is that the most used data pieces get the shortest code, so just '0' is the code for the letter 's'.\nAs mentioned earlier, such normal latin letters are usually stored with UTF-8, which means they take up 8 bits each. So for example the letter 'o' is stored as '01101111' with UTF-8, but it is stored as '110' with our Huffman code for the word 'lossless'.\nNote:\nWith UTF-8, a letter has always the same binary code, but with Huffman code, the binary code for each letter (piece of data) changes with text (data set) we are compressing.\nTo summarize, we have now compressed the word 'lossless' from its UTF-8 code\n01101100 01101111 01110011 01110011 01101100 01100101 01110011 01110011\nto just\n10 110 0 0 10 111 0 0\nusing Huffman Coding, which is a huge improvement.\nBut if data is stored with Huffman Coding as\n10 110 0 0 10 111 0 0\n, or the code is sent to us, how can it be decoded so that we see what information the Huffman code contains?\nFurthermore, the binary code is really\n10110001011100\n, without the spaces, and with variable bit lengths for each piece of data, so how can the computer understand where the binary code for each piece of data starts and ends?\nDecoding Huffman Code\nJust like with code stored as UTF-8, which our computers can already decode to the correct letters, the computer needs to know which bits represent which piece of data in the Huffman code.\nSo along with a Huffman code, there must also be a conversion table with information about what the Huffman binary code is for each piece of data, so that it can be decoded.\nSo, for this Huffman code:\n100110110\nWith this conversion table:\nLetter\nHuffman Code\na\n0\nb\n10\nn\n11\nAre you able to decode the Huffman code?\nHow it works:\nStart from the left in the Huffman code, and look up each bit sequence in the table.\nMatch each code to the corresponding letter.\nContinue until the entire Huffman code is decoded.\nWe start with the first bit:\n1\n0\n0\n1\n1\n0\n1\n1\n0\nThere is no letter in the table with just\n1\nas the Huffman code, so we continue and include the \n1\n0\n0\n1\n1\n0\n1\n1\n0\nWe can see from the table that\n10\nis 'b', so now we have the first letter. We check the \n1\n0\n0\n1\n1\n0\n1\n1\n0\nWe find that\n0\nis 'a', so now we have the two first letters 'ba' stored in the Huffman code.\nWe continue looking up Huffman codes in the table:\n1\n0\n0\n1\n1\n0\n1\n1\n0\nCode\n11\nis 'n'.\n1\n0\n0\n1\n1\n0\n1\n1\n0\nCode\n0\nis 'a'.\n1\n0\n0\n1\n1\n0\n1\n1\n0\nCode\n11\nis 'n'.\n1\n0\n0\n1\n1\n0\n1\n1\n0\nCode\n0\nis 'a'.\nThe Huffman code is now decoded, and the word is 'banana'!\nHuffman Code Prefixes\nAn interesting and very useful part of the Huffman coding algorithm is that it ensures that there is no code that is the prefix of another code.\nJust image if the conversion table we just used, looked like this:\nLetter\nHuffman Code\na\n1\nb\n10\nn\n11\nIf this was the case, we would get confused right from the start of the decoding, right?\n1\n0\n0\n1\n1\n0\n1\n1\n0\nBecause how would we know if the first bit\n1\nrepresents the letter 'a' or if it is the first bit for the letter 'b' or 'c'?\nThis property, that no code is the prefix of another code, makes it possible to decode. And it is especially important in Huffman Coding because of the variable bit lengths.\nHuffman Coding Implementation\nThe correct word for creating Huffman code based on data or text is \"encoding\", and the opposite would be \"decoding\", when the original data or text is recreated based on the code.\nThe code example below takes a word, or any text really, and compress it using Huffman Coding.\nExample\nHuffman Coding.\nclass Node:\n    def __init__(self, char=None, freq=0):\n        self.char = char\n        self.freq = freq\n        self.left = None\n        self.right = None\n\nnodes = []\n\ndef calculate_frequencies(word):\n    frequencies = {}\n    for char in word:\n        if char not in frequencies:\n            freq = word.count(char)\n            frequencies[char] = freq\n            nodes.append(Node(char, freq))\n\ndef build_huffman_tree():\n    while len(nodes) > 1:\n        nodes.sort(key=lambda x: x.freq)\n        left = nodes.pop(0)\n        right = nodes.pop(0)\n\nmerged = Node(freq=left.freq + right.freq)\n        merged.left = left\n        merged.right = right\n\nnodes.append(merged)\n\nreturn nodes[0]\n\ndef generate_huffman_codes(node, current_code, codes):\n    if node is None:\n        return\n\nif node.char is not None:\n        codes[node.char] = current_code\n\ngenerate_huffman_codes(node.left, current_code + '0', codes)\n    generate_huffman_codes(node.right, current_code + '1', codes)\n\ndef huffman_encoding(word):\n    global nodes\n    nodes = []\n    calculate_frequencies(word)\n    root = build_huffman_tree()\n    codes = {}\n    generate_huffman_codes(root, '', codes)\n    return codes\n\nword = \"lossless\"\ncodes = huffman_encoding(word)\nencoded_word = ''.join(codes[char] for char in word)\n\nprint(\"Word:\", word)\nprint(\"Huffman code:\", encoded_word)\nprint(\"Conversion table:\", codes)\nRun Example \u00bb\nHuffman Decoding Implementation\nIn addition to encode data using Huffman coding, we should also have a way to decode it, to recreate the original information.\nThe implementation below is basically the same as the \nThe\nhuffman_decoding\nfunction takes the Huffman code, and the\ncodes\nPython dictionary\n(a\nhashmap\n) with the characters and their corresponding binary codes. The Function then reverse the mapping, and checks the Huffman code bit-by-bit to recreate the original text.\nExample\nHuffman Decoding.\nclass Node:\n    def __init__(self, char=None, freq=0):\n        self.char = char\n        self.freq = freq\n        self.left = None\n        self.right = None\n\nnodes = []\n\ndef calculate_frequencies(word):\n    frequencies = {}\n    for char in word:\n        if char not in frequencies:\n            freq = word.count(char)\n            frequencies[char] = freq\n            nodes.append(Node(char, freq))\n\ndef build_huffman_tree():\n    while len(nodes) > 1:\n        nodes.sort(key=lambda x: x.freq)\n        left = nodes.pop(0)\n        right = nodes.pop(0)\n\nmerged = Node(freq=left.freq + right.freq)\n        merged.left = left\n        merged.right = right\n\nnodes.append(merged)\n\nreturn nodes[0]\n\ndef generate_huffman_codes(node, current_code, codes):\n    if node is None:\n        return\n\nif node.char is not None:\n        codes[node.char] = current_code\n\ngenerate_huffman_codes(node.left, current_code + '0', codes)\n    generate_huffman_codes(node.right, current_code + '1', codes)\n\ndef huffman_encoding(word):\n    global nodes\n    nodes = []\n    calculate_frequencies(word)\n    root = build_huffman_tree()\n    codes = {}\n    generate_huffman_codes(root, '', codes)\n    return codes\n\ndef huffman_decoding(encoded_word, codes):\n    current_code = ''\n    decoded_chars = []\n\n# Invert the codes dictionary to get the reverse mapping\n    code_to_char = {v: k for k, v in codes.items()}\n\nfor bit in encoded_word:\n        current_code += bit\n        if current_code in code_to_char:\n            decoded_chars.append(code_to_char[current_code])\n            current_code = ''\n\nreturn ''.join(decoded_chars)\n\nword = \"lossless\"\ncodes = huffman_encoding(word)\nencoded_word = ''.join(codes[char] for char in word)\ndecoded_word = huffman_decoding(encoded_word, codes)\n\nprint(\"Initial word:\", word)\nprint(\"Huffman code:\", encoded_word)\nprint(\"Conversion table:\", codes)\nprint(\"Decoded word:\", decoded_word)\nRun Example \u00bb\nYou have now seen how a text can be compressed using Huffman coding, and how a Huffman code can be decoded to recreate the original text.\nNote:\nHuffman Coding can be used for lossless compression of any kind of data, not just text. Huffman Coding is also used as a component in other compression algorithms like zip, and even in lossy compressions like jpeg and mp3.\n\n\u2605\n+1",
      "order": 2,
      "code": null,
      "language": null,
      "explanation": null
    }
  ],
  "practice_exercises": [
    {
      "title": "Practice Exercise",
      "description": "Create an example that applies the concepts from this tutorial.",
      "difficulty": "medium",
      "starter_code": "# Add your code here",
      "solution": "# Example solution would go here"
    }
  ],
  "related_topics": [
    {
      "id": "311e348e-a7f9-43b6-be54-9a60cee996b8",
      "title": "C Best Practices",
      "relationship": "related_topic"
    },
    {
      "id": "2d8f2f0f-df24-40aa-9b64-6c9361bdbd96",
      "title": "C Common Pitfalls and How to Avoid Them",
      "relationship": "suggested_reading"
    },
    {
      "id": "5d308a02-afc6-4326-a63e-9729595d6cea",
      "title": "C Fundamentals",
      "relationship": "prerequisite"
    }
  ],
  "quiz": [
    {
      "question": "What is Huffman Coding\n\nHuffman Coding\nHuffman Coding?",
      "options": [
        "also used as a component in many different compression algorithms",
        "an algorithm used for lossless data compression",
        "None of the above.",
        "None of the above."
      ],
      "correct_answer": 1,
      "explanation": "The correct definition of Huffman Coding\n\nHuffman Coding\nHuffman Coding is 'an algorithm used for lossless data compression'."
    },
    {
      "question": "What is Huffman Coding?",
      "options": [
        "an algorithm used for lossless data compression",
        "None of the above.",
        "also used as a component in many different compression algorithms",
        "None of the above."
      ],
      "correct_answer": 2,
      "explanation": "The correct definition of Huffman Coding is 'also used as a component in many different compression algorithms'."
    }
  ],
  "summary": "This tutorial covers Huffman Coding concepts and techniques. You'll learn how to use Huffman Coding effectively, including key principles, common patterns, and practical examples. By the end of this tutorial, you'll have a solid understanding of Huffman Coding and how to apply it in your projects."
}