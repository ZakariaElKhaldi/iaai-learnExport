{
  "id": "606de77c-374c-4644-bd9e-654c1de7fb97",
  "title": "DSAAVL Trees",
  "slug": "dsaavl-trees",
  "metadata": {
    "description": "Learn about DSAAVL Trees with clear explanations and practical examples.",
    "keywords": [
      "node",
      "right",
      "left",
      "tree",
      "balance",
      "rotation",
      "nodes",
      "height",
      "unbalanced",
      "case"
    ],
    "difficulty": "intermediate",
    "prerequisites": [],
    "estimated_time": 15,
    "category": "LearnDSA",
    "subcategory": "DSA AVL Trees"
  },
  "content_sections": [
    {
      "type": "introduction",
      "title": "DSA\nAVL Trees\n\nThe\nAVL\nTree is a type of Binary Search Tree named after two Soviet inventors Georgy\nA\ndelson",
      "content": "-\nV\nelsky and Evgenii\nL\nandis who invented the AVL Tree in 1962.\nAVL trees are self-balancing, which means that the tree height is kept to a minimum so that a very fast runtime is guaranteed for searching, inserting and deleting nodes, with time complexity \\(O( \\log n)\\).\nAVL Trees\nThe only difference between a regular\nBinary Search Tree\nand an AVL Tree is that AVL Trees do rotation operations in addition, to keep the tree balance.\nA Binary Search Tree is in balance when the difference in height between left and right subtrees is less than 2.\nBy keeping balance, the AVL Tree ensures a minimum tree height, which means that search, insert, and delete operations can be done really fast.\nB\nG\nE\nK\nF\nP\nI\nM\nBinary Search Tree\n(unbalanced)\nHeight: 6\nG\nE\nK\nB\nF\nI\nP\nM\nAVL Tree\n(self-balancing)\nHeight: 3\nThe two trees above are both Binary Search Trees, they have the same nodes, and the same in-order traversal (alphabetical), but the height is very different because the AVL Tree has balanced itself.\nStep through the building of an AVL Tree in the animation below to see how the balance factors are updated, and how rotation operations are done when required to restore the balance.\n0\nC\n0\nF\n0\nG\n0\nD\n0\nB\n0\nA\nInsert C\nContinue reading to learn more about how the balance factor is calculated, how rotation operations are done, and how AVL Trees can be implemented.\nLeft and Right Rotations\nTo restore balance in an AVL Tree, left or right rotations are done, or a combination of left and right rotations.\nThe \nBut in general, left and right rotations are done like in the animation below.\nX\nY\nRotate Right\nNotice how the subtree changes its parent. Subtrees change parent in this way during rotation to maintain the correct in-order traversal, and to maintain the BST property that the left child is less than the right child, for all nodes in the tree.\nAlso keep in mind that it is not always the root node that become unbalanced and need rotation.\nThe Balance Factor\nA node's balance factor is the difference in subtree heights.\nThe subtree heights are stored at each node for all nodes in an AVL Tree, and the balance factor is calculated based on its subtree heights to check if the tree has become out of balance.\nThe height of a subtree is the number of edges between the root node of the subtree and the leaf node farthest down in that subtree.\nThe\nBalance Factor\n(\\(BF\\)) for a node (\\(X\\)) is the difference in height between its right and left subtrees.\n\\[ BF(X) = height(rightSubtree(X)) - height(leftSubtree(X)) \\]\nBalance factor values\n0: The node is in balance.\nmore than 0: The node is \"right heavy\".\nless than 0: The node is \"left heavy\".\nIf the balance factor is less than -1, or more than 1, for one or more nodes in the tree, the tree is considered not in balance, and a rotation operation is needed to restore balance.\nLet's take a closer look at the different rotation operations that an AVL Tree can do to regain balance.\nThe Four \"out-of-balance\" Cases\nWhen the balance factor of just one node is less than -1, or more than 1, the tree is regarded as out of balance, and a rotation is needed to restore balance.\nThere are four different ways an AVL Tree can be out of balance, and each of these cases require a different rotation operation.\nCase\nDescription\nRotation to Restore Balance\nLeft-Left (LL)\nThe unbalanced node and its left child node are both left-heavy.\nA single right rotation.\nRight-Right (RR)\nThe unbalanced node and its right child node are both right-heavy.\nA single left rotation.\nLeft-Right (LR)\nThe unbalanced node is left heavy, and its left child node is right heavy.\nFirst do a left rotation on the left child node, then do a right rotation on the unbalanced node.\nRight-Left (RL)\nThe unbalanced node is right heavy, and its right child node is left heavy.\nFirst do a right rotation on the right child node, then do a left rotation on the unbalanced node.\nSee animations and explanations of these cases below.\nThe Left-Left (LL) Case\nThe node where the unbalance is discovered is left heavy, and the node's left child node is also left heavy.\nWhen this LL case happens, a single right rotation on the unbalanced node is enough to restore balance.\nStep through the animation below to see the LL case, and how the balance is restored by a single right rotation.\n-1\nQ\n0\nP\n0\nD\n0\nL\n0\nC\n0\nB\n0\nK\n0\nA\nInsert D\nAs you step through the animation above, two LL cases happen:\nWhen D is added, the balance factor of Q becomes -2, which means the tree is unbalanced. This is an LL case because both the unbalance node Q and its left child node P are left heavy (negative balance factors). A single right rotation at node Q restores the tree balance.\nAfter nodes L, C, and B are added, P's balance factor is -2, which means the tree is out of balance. This is also an LL case because both the unbalanced node P and its left child node D are left heavy. A single right rotation restores the balance.\nNote:\nThe second time the LL case happens in the animation above, a right rotation is done, and L goes from being the right child of D to being the left child of P. Rotations are done like that to keep the correct in-order traversal ('B, C, D, L, P, Q' in the animation above). Another reason for changing parent when a rotation is done is to keep the BST property, that the left child is always lower than the node, and that the right child always higher.\nThe Right-Right (RR) Case\nA Right-Right case happens when a node is unbalanced and right heavy, and the right child node is also right heavy.\nA single left rotation at the unbalanced node is enough to restore balance in the RR case.\n+1\nA\n0\nB\n0\nD\n0\nC\n0\nE\n0\nF\nInsert D\nThe RR case happens two times in the animation above:\nWhen node D is inserted, A becomes unbalanced, and bot A and B are right heavy. A left rotation at node A restores the tree balance.\nAfter nodes E, C and F are inserted, node B becomes unbalanced. This is an RR case because both node B and its right child node D are right heavy. A left rotation restores the tree balance.\nThe Left-Right (LR) Case\nThe Left-Right case is when the unbalanced node is left heavy, but its left child node is right heavy.\nIn this LR case, a left rotation is first done on the left child node, and then a right rotation is done on the original unbalanced node.\nStep through the animation below to see how the Left-Right case can happen, and how the rotation operations are done to restore balance.\n-1\nQ\n0\nE\n0\nK\n0\nC\n0\nF\n0\nG\nInsert D\nAs you are building the AVL Tree in the animation above, the Left-Right case happens 2 times, and rotation operations are required and done to restore balance:\nWhen K is inserted, node Q gets unbalanced with a balance factor of -2, so it is left heavy, and its left child E is right heavy, so this is a Left-Right case.\nAfter nodes C, F, and G are inserted, node K becomes unbalanced and left heavy, with its left child node E right heavy, so it is a Left-Right case.\nThe Right-Left (RL) Case\nThe Right-Left case is when the unbalanced node is right heavy, and its right child node is left heavy.\nIn this case we first do a right rotation on the unbalanced node's right child, and then we do a left rotation on the unbalanced node itself.\nStep through the animation below to see how the Right-Left case can occur, and how rotations are done to restore the balance.\n+1\nA\n0\nF\n0\nB\n0\nG\n0\nE\n0\nD\nInsert B\nAfter inserting node B, we get a Right-Left case because node A becomes unbalanced and right heavy, and its right child is left heavy. To restore balance, a right rotation is first done on node F, and then a left rotation is done on node A.\nThe \nRetracing in AVL Trees\nAfter inserting or deleting a node in an AVL tree, the tree may become unbalanced. To find out if the tree is unbalanced, we need to update the heights and recalculate the balance factors of all ancestor nodes.\nThis process, known as retracing, is handled through recursion. As the recursive calls propagate back to the root after an insertion or deletion, each ancestor node's height is updated and the balance factor is recalculated. If any ancestor node is found to have a balance factor outside the range of -1 to 1, a rotation is performed at that node to restore the tree's balance.\nIn the simulation below, after inserting node F, the nodes C, E and H are all unbalanced, but since retracing works through recursion, the unbalance at node H is discovered and fixed first, which in this case also fixes the unbalance in nodes E and C.\n-1\nA\n0\nB\n0\nC\n0\nD\n0\nE\n0\nG\n0\nH\n0\nF\nInsert F\nAfter node F is inserted, the code will retrace, calculating balancing factors as it propagates back up towards the root node. When node H is reached and the balancing factor -2 is calculated, a right rotation is done. Only after this rotation is done, the code will continue to retrace, calculating balancing factors further up on ancestor nodes E and C.\nBecause of the rotation, balancing factors for nodes E and C stay the same as before node F was inserted.\nAVL Insert Node Implementation\nThis code is based on the BST implementation on the \nThere is only one new attribute for each node in the AVL tree compared to the BST, and that is the height, but there are many new functions and extra code lines needed for the AVL Tree implementation because of how the AVL Tree rebalances itself.\nThe implementation below builds an AVL tree based on a list of characters, to create the AVL Tree in the simulation above. The last node to be inserted 'F', also triggers a right rotation, just like in the simulation above.\nExample\nPython:\nclass TreeNode:\n    def __init__(self, data):\n        self.data = data\n        self.left = None\n        self.right = None\n        self.height = 1\n\ndef getHeight(node):\n    if not node:\n        return 0\n    return node.height\n\ndef getBalance(node):\n    if not node:\n        return 0\n    return getHeight(node.left) - getHeight(node.right)\n\ndef rightRotate(y):\n    print('Rotate right on node',y.data)\n    x = y.left\n    T2 = x.right\n    x.right = y\n    y.left = T2\n    y.height = 1 + max(getHeight(y.left), getHeight(y.right))\n    x.height = 1 + max(getHeight(x.left), getHeight(x.right))\n    return x\n\ndef leftRotate(x):\n    print('Rotate left on node',x.data)\n    y = x.right\n    T2 = y.left\n    y.left = x\n    x.right = T2\n    x.height = 1 + max(getHeight(x.left), getHeight(x.right))\n    y.height = 1 + max(getHeight(y.left), getHeight(y.right))\n    return y\n\ndef insert(node, data):\n    if not node:\n        return TreeNode(data)\n\n    if data < node.data:\n        node.left = insert(node.left, data)\n    elif data > node.data:\n        node.right = insert(node.right, data)\n\n    # Update the balance factor and balance the tree\n    node.height = 1 + max(getHeight(node.left), getHeight(node.right))\n    balance = getBalance(node)\n\n    # Balancing the tree\n    # Left Left\n    if balance > 1 and getBalance(node.left) >= 0:\n        return rightRotate(node)\n\n    # Left Right\n    if balance > 1 and getBalance(node.left) < 0:\n        node.left = leftRotate(node.left)\n        return rightRotate(node)\n\n    # Right Right\n    if balance < -1 and getBalance(node.right) <= 0:\n        return leftRotate(node)\n\n    # Right Left\n    if balance < -1 and getBalance(node.right) > 0:\n        node.right = rightRotate(node.right)\n        return leftRotate(node)\n\n    return node\n\ndef inOrderTraversal(node):\n    if node is None:\n        return\n    inOrderTraversal(node.left)\n    print(node.data, end=\", \")\n    inOrderTraversal(node.right)",
      "order": 1,
      "code": null,
      "language": null,
      "explanation": null
    },
    {
      "type": "concept",
      "title": "Section 2",
      "content": "# Inserting nodes\nroot = None\nletters = ['C', 'B', 'E', 'A', 'D', 'H', 'G', 'F']\nfor letter in letters:\n    root = insert(root, letter)\n\ninOrderTraversal(root)\nRun Example \u00bb\nAVL Delete Node Implementation\nWhen deleting a node that is not a leaf node, the AVL Tree requires the\nminValueNode()\nfunction to find a node's \nTo delete a node in an AVL Tree, the same code to restore balance is needed as for the code to insert a node.\nExample\nPython:\ndef minValueNode(node):\n    current = node\n    while current.left is not None:\n        current = current.left\n    return current\n\ndef delete(node, data):\n    if not node:\n        return node\n\n    if data < node.data:\n        node.left = delete(node.left, data)\n    elif data > node.data:\n        node.right = delete(node.right, data)\n    else:\n        if node.left is None:\n            temp = node.right\n            node = None\n            return temp\n        elif node.right is None:\n            temp = node.left\n            node = None\n            return temp\n\n        temp = minValueNode(node.right)\n        node.data = temp.data\n        node.right = delete(node.right, temp.data)\n\n    if node is None:\n        return node\n\n    # Update the balance factor and balance the tree\n    node.height = 1 + max(getHeight(node.left), getHeight(node.right))\n    balance = getBalance(node)\n\n    # Balancing the tree\n    # Left Left\n    if balance > 1 and getBalance(node.left) >= 0:\n        return rightRotate(node)\n\n    # Left Right\n    if balance > 1 and getBalance(node.left) < 0:\n        node.left = leftRotate(node.left)\n        return rightRotate(node)\n\n    # Right Right\n    if balance < -1 and getBalance(node.right) <= 0:\n        return leftRotate(node)\n\n    # Right Left\n    if balance < -1 and getBalance(node.right) > 0:\n        node.right = rightRotate(node.right)\n        return leftRotate(node)\n\n    return node\nRun Example \u00bb\nTime Complexity for AVL Trees\nTake a look at the unbalanced Binary Search Tree below. Searching for \"M\" means that all nodes except 1 must be compared. But searching for \"M\" in the AVL Tree below only requires us to visit 4 nodes.\nSo in worst case, algorithms like search, insert, and delete must run through the whole height of the tree. This means that keeping the height (\\(h \\)) of the tree low, like we do using AVL Trees, gives us a lower runtime.\nB\nG\nE\nK\nF\nP\nI\nM\nBinary Search Tree\n(unbalanced)\nG\nE\nK\nB\nF\nI\nP\nM\nAVL Tree\n(self-balancing)\nSee the comparison of the time complexities between Binary Search Trees and AVL Trees below, and how the time complexities relate to the height (\\(h\\)) of the tree, and the number of nodes (\\(n\\)) in the tree.\nThe\nBST\nis not self-balancing. This means that a BST can be very unbalanced, almost like a long chain, where the height is nearly the same as the number of nodes. This makes operations like searching, deleting and inserting nodes slow, with time complexity \\(O(h) = O(n)\\).\nThe\nAVL Tree\nhowever is self-balancing. That means that the height of the tree is kept to a minimum so that operations like searching, deleting and inserting nodes are much faster, with time complexity \\(O(h) = O( \\log n)\\).\n\\(O( \\log n)\\) Explained\nThe fact that the time complexity is \\(O(h) = O( \\log n)\\) for search, insert, and delete on an AVL Tree with height \\(h\\) and nodes \\(n\\) can be explained like this:\nImagine a perfect Binary Tree where all nodes have two child nodes except on the lowest level, like the AVL Tree below.\nH\nD\nB\nF\nE\nG\nA\nC\nL\nJ\nN\nM\nO\nI\nK\nThe number of nodes on each level in such an AVL Tree are:\n\\[1, 2, 4, 8, 16, 32, ..\\]\nWhich is the same as:\n\\[2^0, 2^1, 2^2, 2^3, 2^4, 2^5, ..\\]\nTo get the number of nodes \\(n\\) in a perfect Binary Tree with height \\(h=3\\), we can add the number of nodes on each level together:\n\\[n_3=2^0 + 2^1 + 2^2 + 2^3 = 15\\]\nWhich is actually the same as:\n\\[n_3=2^4 - 1 = 15\\]\nAnd this is actually the case for larger trees as well! If we want to get the number of nodes \\(n \\) in a tree with height \\(h=5 \\) for example, we find the number of nodes like this:\n\\[n_5=2^6 - 1 = 63\\]\nSo in general, the relationship between the height \\(h \\) of a perfect Binary Tree and the number of nodes in it \\(n \\), can be expressed like this:\n\\[n_h = 2^{h+1} - 1\\]\nNote:\nThe formula above can also be found by calculating the sum of the geometric series \\(2^0 + 2^1 + 2^2+  2^3 + ... + 2^n \\)\nWe know that the time complexity for searching, deleting, or inserting a node in an AVL tree is \\(O(h) \\), but we want to argue that the time complexity is actually \\(O(\\log(n)) \\), so we need to find the height \\(h\\) described by the number of nodes \\(n\\):\n\\[\n\\begin{equation}\n\\begin{aligned}\nn             & = 2^{h+1}-1 \\\\\nn+1           & = 2^{h+1} \\\\\n\\log_2(n+1)   & = \\log_2(2^{h+1}) \\\\\nh             & = \\log_2(n+1) - 1 \\\\\n\\\\\nO(h)          & = O(\\log{n})\n\\end{aligned}\n\\end{equation}\n\\]\nHow the last line above is derived might not be obvious, but for a Binary Tree with a lot of nodes (big \\(n\\)), the \"+1\" and \"-1\" terms are not important when we consider time complexity. For more details on how to calculate the time complexity using Big O notation, see\nthis page\n.\nThe math above shows that the time complexity for search, delete, and insert operations on an AVL Tree \\(O(h) \\), can actually be expressed as \\(O(\\log{n}) \\), which is fast, a lot faster than the time complexity for BSTs which is \\(O(n) \\).\nDSA Exercises\nTest Yourself With Exercises\nExercise:\nEach node in the AVL Tree below is displayed together with its balance factor:\nWhat is the balance factor?\nThe balance factor is the \ndifference between each node's \nleft and right subtree\n.\nSubmit Answer \u00bb\nStart the Exercise\n\n\u2605\n+1",
      "order": 2,
      "code": null,
      "language": null,
      "explanation": null
    }
  ],
  "practice_exercises": [
    {
      "title": "Implement a Function",
      "description": "Create a function that demonstrates the concepts from this tutorial.",
      "difficulty": "medium",
      "starter_code": "# Write your python function here\n",
      "solution": "# Example solution would go here"
    }
  ],
  "related_topics": [
    {
      "id": "d4832f3b-2144-4aa0-85ee-508907d0fd1f",
      "title": "Unknown Best Practices",
      "relationship": "related_topic"
    },
    {
      "id": "2b4cb914-80f1-4d44-b113-b7924582292a",
      "title": "Unknown Common Pitfalls and How to Avoid Them",
      "relationship": "suggested_reading"
    },
    {
      "id": "9431920b-da22-455f-806e-83139233c300",
      "title": "Unknown Fundamentals",
      "relationship": "prerequisite"
    }
  ],
  "quiz": [
    {
      "question": "What is DSA\nAVL Trees\n\nThe\nAVL\nTree?",
      "options": [
        "a type of Binary Search Tree named after two Soviet inventors Georgy\nA\ndelson-\nV\nelsky and Evgenii\nL\nandis who invented the AVL Tree in 1962",
        "self-balancing",
        "None of the above.",
        "None of the above."
      ],
      "correct_answer": 0,
      "explanation": "The correct definition of DSA\nAVL Trees\n\nThe\nAVL\nTree is 'a type of Binary Search Tree named after two Soviet inventors Georgy\nA\ndelson-\nV\nelsky and Evgenii\nL\nandis who invented the AVL Tree in 1962'."
    },
    {
      "question": "What is AVL trees?",
      "options": [
        "self-balancing",
        "a type of Binary Search Tree named after two Soviet inventors Georgy\nA\ndelson-\nV\nelsky and Evgenii\nL\nandis who invented the AVL Tree in 1962",
        "None of the above.",
        "None of the above."
      ],
      "correct_answer": 0,
      "explanation": "The correct definition of AVL trees is 'self-balancing'."
    }
  ],
  "summary": "This tutorial covers DSAAVL Trees concepts and techniques. You'll learn how to use DSAAVL Trees effectively, including key principles, common patterns, and practical examples. By the end of this tutorial, you'll have a solid understanding of DSAAVL Trees and how to apply it in your projects."
}